{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7OGa4HIb0Pc",
        "outputId": "30c830d9-b237-463f-dd7a-dd1d6a69b955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Name: Tesla T4\n",
            "GPU Is Available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check PyTorch GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Is Available: {torch.cuda.is_available()}\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/pakshi10/yolov9-custom.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VNoXtgrb-Ot",
        "outputId": "07827f58-0f16-4bd3-dedc-8a9fadd18c4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9-custom'...\n",
            "remote: Enumerating objects: 1466, done.\u001b[K\n",
            "remote: Counting objects: 100% (1076/1076), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1062/1062), done.\u001b[K\n",
            "remote: Total 1466 (delta 31), reused 1052 (delta 14), pack-reused 390\u001b[K\n",
            "Receiving objects: 100% (1466/1466), 28.66 MiB | 32.90 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIS6e2mwcbMK",
        "outputId": "29bf65f1-3405-4eee-df1d-bb5b33787ea0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34myolov9-custom\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P yolov9-custom/ https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c-seg.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5-ZuBjjcbPE",
        "outputId": "539fbbf7-5567-4842-e972-509c40b77e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-22 13:58:43--  https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c-seg.pt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/8e84a45a-6385-4f58-9beb-2b45baf38685?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240422T135843Z&X-Amz-Expires=300&X-Amz-Signature=0a2b153bfc45c04650f34efacc77e197c4d7fc550cf99cd8f54048e55b3aec54&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=759338070&response-content-disposition=attachment%3B%20filename%3Dyolov9-c-seg.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-22 13:58:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/8e84a45a-6385-4f58-9beb-2b45baf38685?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240422T135843Z&X-Amz-Expires=300&X-Amz-Signature=0a2b153bfc45c04650f34efacc77e197c4d7fc550cf99cd8f54048e55b3aec54&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=759338070&response-content-disposition=attachment%3B%20filename%3Dyolov9-c-seg.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116904429 (111M) [application/octet-stream]\n",
            "Saving to: ‘yolov9-custom/yolov9-c-seg.pt’\n",
            "\n",
            "yolov9-c-seg.pt     100%[===================>] 111.49M   128MB/s    in 0.9s    \n",
            "\n",
            "2024-04-22 13:58:44 (128 MB/s) - ‘yolov9-custom/yolov9-c-seg.pt’ saved [116904429/116904429]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov9-custom/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apMIfxuDcbSd",
        "outputId": "ebcf6a2c-538e-4801-825e-361ce1e52ed6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov9-custom/'\n",
            "/content/yolov9-custom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o96ZFr-cbVU",
        "outputId": "30f9944b-4178-4b8f-c20a-2a08679fe7e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmarks.py  detect_dual.py       \u001b[0m\u001b[01;34mfigure\u001b[0m/     README.md         train_dual.py    val.py\n",
            "\u001b[01;34mclassify\u001b[0m/      detect.py            hubconf.py  requirements.txt  train.py         val_triple.py\n",
            "config.yaml    docker-compose.yaml  LICENSE.md  \u001b[01;34mscripts\u001b[0m/          train_triple.py  yolov9-c-seg.pt\n",
            "\u001b[01;34mdata\u001b[0m/          Dockerfile           \u001b[01;34mmodels\u001b[0m/     \u001b[01;34msegment\u001b[0m/          \u001b[01;34mutils\u001b[0m/\n",
            "data.yaml      export.py            \u001b[01;34mpanoptic\u001b[0m/   \u001b[01;34mtools\u001b[0m/            val_dual.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python segment/train_with_config.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5xQeHBlcbYd",
        "outputId": "e162c83b-6728-4ecf-8d9a-b0b658f61c6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 15:30:40.404960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 15:30:40.405017: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 15:30:40.406465: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 15:30:41.943628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Configuration loaded for training:\n",
            "Namespace(weights='yolov9-c-seg.pt', cfg='models/segment/yolov9-c-dseg.yaml', data='data.yaml', hyp='hyp.scratch-high.yaml', epochs=20, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket='', cache=None, image_weights=False, device='', multi_scale=False, single_cls=False, optimizer='SGD', sync_bn=False, workers=8, project='runs/train-seg', name='exp', exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, close_mosaic=0, mask_ratio=4, no_overlap=False)\n",
            "Training will run for 20 epochs with a batch size of 2.\n",
            "\u001b[34m\u001b[1msegment/train_with_config: \u001b[0mweights=yolov9-c-seg.pt, cfg=models/segment/yolov9-c-dseg.yaml, data=data.yaml, hyp=hyp.scratch-high.yaml, epochs=20, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-seg, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, close_mosaic=0, mask_ratio=4, no_overlap=False\n",
            "Training with the following options:\n",
            "Namespace(weights='yolov9-c-seg.pt', cfg='models/segment/yolov9-c-dseg.yaml', data='data.yaml', hyp='hyp.scratch-high.yaml', epochs=20, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket='', cache=None, image_weights=False, device='', multi_scale=False, single_cls=False, optimizer='SGD', sync_bn=False, workers=8, project='runs/train-seg', name='exp', exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, close_mosaic=0, mask_ratio=4, no_overlap=False)\n",
            "YOLO 🚀 7dcbf2c Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-seg', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1         0  models.common.Silence                   []                            \n",
            "  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  8                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            " 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
            " 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 17                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 20                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 23                 5  1    131328  models.common.CBLinear                  [512, [256]]                  \n",
            " 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]             \n",
            " 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]        \n",
            " 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            " 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            " 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            " 29                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n",
            " 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            " 32                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n",
            " 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            " 35                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n",
            " 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            " 38                31  1   1069568  models.common.RepNCSPELAN4              [512, 512, 256, 128, 2]       \n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 41                16  1    872448  models.common.RepNCSPELAN4              [256, 256, 256, 128, 2]       \n",
            " 42                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 43                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 44[31, 34, 37, 16, 19, 22, 40, 43]  1  24670004  models.yolo.DualDSegment                [14, 32, 256, [512, 512, 512, 256, 512, 512, 256, 256]]\n",
            "yolov9-c-dseg summary: 1204 layers, 57839284 parameters, 57839252 gradients\n",
            "\n",
            "Transferred 1820/1832 items from yolov9-c-seg.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 298 weight(decay=0.0), 321 weight(decay=0.0005), 319 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov9-custom/data/fashion/train/labels.cache... 350 images, 1 backgrounds, 2 corrupt: 100% 351/351 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov9-custom/data/fashion/train/images/059313.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0027]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov9-custom/data/fashion/train/images/110168.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0022]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov9-custom/data/fashion/val/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100% 100/100 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/train-seg/exp3/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-seg/exp3\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       0/19      4.29G      1.559      1.444      4.863      2.064          5        640: 100% 175/175 [01:14<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:07<00:00,  3.26it/s]\n",
            "                   all        100        165      0.294      0.239      0.109     0.0574      0.283      0.218      0.087     0.0385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/19       4.9G      1.217      1.197      3.731      1.745          5        640: 100% 175/175 [01:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.04it/s]\n",
            "                   all        100        165      0.115      0.339      0.155      0.104      0.108      0.321       0.13     0.0707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/19      4.91G      1.189      1.095      3.467      1.676         10        640: 100% 175/175 [01:12<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.82it/s]\n",
            "                   all        100        165      0.325      0.208      0.151     0.0972      0.408      0.197      0.132     0.0724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/19      4.91G      1.231      1.122      3.447      1.747          2        640: 100% 175/175 [01:12<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.06it/s]\n",
            "                   all        100        165      0.169      0.364      0.198      0.136      0.167      0.352      0.191      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/19      4.91G      1.306      1.177      3.239      1.769          7        640: 100% 175/175 [01:12<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.10it/s]\n",
            "                   all        100        165      0.268      0.429      0.242      0.172      0.258      0.335      0.222      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/19      4.91G      1.344      1.174      3.082       1.77          5        640: 100% 175/175 [01:13<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.05it/s]\n",
            "                   all        100        165      0.263      0.312      0.229      0.166      0.263       0.31      0.218      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/19      4.91G      1.343       1.26      3.028      1.763          8        640: 100% 175/175 [01:14<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.08it/s]\n",
            "                   all        100        165      0.169      0.383       0.25      0.173      0.503      0.241      0.226      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/19      4.91G      1.323      1.163      2.914       1.74         11        640: 100% 175/175 [01:12<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.66it/s]\n",
            "                   all        100        165       0.38      0.343      0.246      0.175      0.375       0.33      0.232      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/19      4.91G      1.346      1.167      2.892      1.774          1        640: 100% 175/175 [01:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.14it/s]\n",
            "                   all        100        165      0.253       0.39      0.258      0.174      0.455      0.281      0.235      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/19      4.91G        1.3      1.131      2.784      1.751          6        640: 100% 175/175 [01:13<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.55it/s]\n",
            "                   all        100        165      0.267       0.43      0.285      0.199       0.27      0.354      0.262      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/19      4.91G      1.314       1.14       2.78      1.745          7        640: 100% 175/175 [01:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.10it/s]\n",
            "                   all        100        165      0.225      0.421      0.284      0.199      0.199       0.36      0.245      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/19      4.91G      1.295      1.123      2.709      1.724          2        640: 100% 175/175 [01:12<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.64it/s]\n",
            "                   all        100        165      0.334      0.385      0.264      0.192      0.336      0.381      0.255      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/19      4.91G      1.315      1.129      2.651      1.765          5        640: 100% 175/175 [01:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.39it/s]\n",
            "                   all        100        165      0.312      0.386      0.271      0.193      0.374      0.266      0.254      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/19      4.91G      1.216      1.055      2.514      1.703          5        640: 100% 175/175 [01:12<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.08it/s]\n",
            "                   all        100        165      0.408      0.463      0.369      0.273      0.338      0.424      0.314      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/19      4.91G      1.161      1.026      2.406      1.653          7        640: 100% 175/175 [01:12<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.90it/s]\n",
            "                   all        100        165      0.548      0.329      0.325      0.243      0.439      0.351      0.295      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/19      4.91G      1.138     0.9973      2.368      1.624          4        640: 100% 175/175 [01:12<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.04it/s]\n",
            "                   all        100        165      0.262      0.416       0.35      0.251      0.266      0.405       0.33       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/19      4.91G      1.142      1.074      2.317       1.64         10        640: 100% 175/175 [01:13<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.39it/s]\n",
            "                   all        100        165      0.238      0.523       0.34      0.253      0.232      0.429      0.307      0.195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/19      4.91G      1.109      1.037      2.335      1.616          6        640: 100% 175/175 [01:13<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.05it/s]\n",
            "                   all        100        165      0.371      0.461      0.316      0.232      0.367      0.418      0.293      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/19      4.91G       1.08     0.9945      2.253      1.596          6        640: 100% 175/175 [01:12<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:04<00:00,  5.11it/s]\n",
            "                   all        100        165      0.399      0.416      0.347      0.261      0.394      0.389       0.32      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/19      4.91G       1.05     0.9578      2.127      1.573          6        640: 100% 175/175 [01:13<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.45it/s]\n",
            "                   all        100        165      0.422      0.441       0.37      0.278      0.425      0.414      0.337      0.221\n",
            "\n",
            "20 epochs completed in 0.479 hours.\n",
            "Optimizer stripped from runs/train-seg/exp3/weights/last.pt, 116.6MB\n",
            "Optimizer stripped from runs/train-seg/exp3/weights/best.pt, 116.6MB\n",
            "\n",
            "Validating runs/train-seg/exp3/weights/best.pt...\n",
            "Fusing layers... \n",
            "yolov9-c-dseg summary: 746 layers, 57498612 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 25/25 [00:05<00:00,  4.22it/s]\n",
            "                   all        100        165       0.42      0.441       0.37      0.278      0.423      0.414      0.337       0.22\n",
            "      short sleeve top        100         39      0.447      0.769      0.595      0.484      0.426      0.718      0.557       0.38\n",
            "       long sleeve top        100         18      0.314      0.444      0.389      0.268      0.321      0.444      0.359      0.187\n",
            "   long sleeve outwear        100          8          1          0     0.0938     0.0438          1          0     0.0422     0.0243\n",
            "                  vest        100          6      0.576      0.167       0.25      0.121      0.644      0.167      0.233       0.16\n",
            "                shorts        100         16      0.465      0.688      0.613      0.441      0.468      0.688      0.612      0.394\n",
            "              trousers        100         30      0.709      0.767      0.815      0.629      0.704      0.713      0.756      0.524\n",
            "                 skirt        100         16      0.237       0.25      0.242      0.194      0.302      0.312       0.27      0.184\n",
            "    short sleeve dress        100          6      0.217      0.667      0.372      0.345      0.219      0.667      0.372      0.283\n",
            "     long sleeve dress        100          7          0          0     0.0842     0.0722          0          0     0.0842     0.0469\n",
            "            vest dress        100         15      0.454        0.6      0.391      0.296      0.461        0.6      0.372      0.226\n",
            "           sling dress        100          4      0.202        0.5      0.224      0.161      0.113       0.25      0.053     0.0136\n",
            "Results saved to \u001b[1mruns/train-seg/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect_dual.py --img 640 --conf 0.1 --device 0 --weights /content/yolov9-custom/runs/train-seg/exp3/weights/best.pt --source /content/yolov9-custom/data/fashion/test/images/001604.jpg"
      ],
      "metadata": {
        "id": "XOek6iBKLlzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c813956-6d10-41d7-d61a-a2ca14b761ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/yolov9-custom/runs/train-seg/exp3/weights/best.pt'], source=/content/yolov9-custom/data/fashion/test/images/001604.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLO 🚀 7dcbf2c Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "yolov9-c-dseg summary: 746 layers, 57498612 parameters, 0 gradients\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9-custom/detect_dual.py\", line 232, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9-custom/detect_dual.py\", line 227, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov9-custom/detect_dual.py\", line 99, in run\n",
            "    pred = pred[0][1]\n",
            "IndexError: index 1 is out of bounds for dimension 0 with size 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgJo-oLhcbbn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}